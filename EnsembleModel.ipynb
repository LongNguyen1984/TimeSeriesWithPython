{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EnsembleModel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvpTndKelbK0yNa5sTFzb4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LongNguyen1984/TimeSeriesWithPython/blob/main/EnsembleModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwtLyvOIGSAt",
        "outputId": "58fb301b-1c2c-4b45-d2af-b082347163b0"
      },
      "source": [
        "# argmax function\n",
        "def argmax(vector):\n",
        "  index, value = 0, vector[0]\n",
        "  for i, v in enumerate(vector):\n",
        "    if v > value:\n",
        "      index, value = i,v\n",
        "  return index\n",
        "\n",
        "# define vector \n",
        "vector = [0.4, 0.5 ,0.1]\n",
        "print('arg max of %s: %d'%(vector, argmax(vector)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arg max of [0.4, 0.5, 0.1]: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R40dfclJiS6"
      },
      "source": [
        "# model averaging ensemble and a study of ensemble size on test accuracy\n",
        "from sklearn.datasets import make_blobs\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# fit model on dataset\n",
        "def fit_model(trainX, trainy):\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(15, input_dim=2, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainy, epochs=200, verbose=0)\n",
        "\treturn model\n",
        " \n",
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, testX):\n",
        "\t# make predictions\n",
        "  yhats = [model.predict(testX) for model in members]\n",
        "  yhats = array(yhats)\n",
        "  #print(yhats)\n",
        "  # sum across ensemble members\n",
        "  summed = numpy.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "  result = argmax(summed, axis=1)\n",
        "  return result\n",
        " \n",
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "\t# select a subset of members\n",
        "\tsubset = members[:n_members]\n",
        "\tprint(len(subset))\n",
        "\t# make prediction\n",
        "\tyhat = ensemble_predictions(subset, testX)\n",
        "\t# calculate accuracy\n",
        "\treturn accuracy_score(testy, yhat)\n",
        " \n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=500, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# split into train and test\n",
        "n_train = int(0.3 * X.shape[0])\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "trainy = to_categorical(trainy)\n",
        "# fit all models\n",
        "n_members = 20\n",
        "members = [fit_model(trainX, trainy) for _ in range(n_members)]\n",
        "# evaluate different numbers of ensembles\n",
        "scores = list()\n",
        "for i in range(1, n_members+1):\n",
        "\tscore = evaluate_n_members(members, i, testX, testy)\n",
        "\tprint('> %.3f' % score)\n",
        "\tscores.append(score)\n",
        "# plot score vs number of ensemble members\n",
        "x_axis = [i for i in range(1, n_members+1)]\n",
        "pyplot.plot(x_axis, scores)\n",
        "pyplot.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-67IGDpZO9M"
      },
      "source": [
        "yhats = [ members[i].predict(testX) for i in range(0,2)]\n",
        "yhats = array(yhats)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-O1G8tSZtcL"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "summed = np.sum(yhats, axis=0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTPS2-XeazWp",
        "outputId": "bd060a42-bcc7-43fb-d634-00d71b9bd8c9"
      },
      "source": [
        "np.shape(yhats)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 350, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItwVztOzatqe",
        "outputId": "f024098f-e9bf-4c76-eead-28322e8ddc4a"
      },
      "source": [
        "np.shape(summed), summed"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((350, 3), array([[7.3212802e-01, 3.8570255e-01, 8.8216925e-01],\n",
              "        [1.1392098e-03, 1.9987142e+00, 1.4637104e-04],\n",
              "        [4.3660045e-01, 3.7906772e-01, 1.1843319e+00],\n",
              "        ...,\n",
              "        [3.3777374e-01, 1.0990586e+00, 5.6316769e-01],\n",
              "        [6.6449061e-02, 1.1954141e+00, 7.3813683e-01],\n",
              "        [1.9643010e-01, 1.4158821e+00, 3.8768786e-01]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGhOXukBW1Qu",
        "outputId": "773af5fd-aefa-4024-a6ec-9fde2640ccbd"
      },
      "source": [
        "testX[0:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.30956392,  -4.87316732],\n",
              "       [  4.81845091,  -1.38407855],\n",
              "       [ -0.68524041,  -4.15563282],\n",
              "       [ -0.27433912, -11.97205154],\n",
              "       [  1.75965848,  -2.12754045],\n",
              "       [ -0.7972227 ,  -8.48662407],\n",
              "       [ -0.28758826,  -1.47819873],\n",
              "       [  5.64603136,  -2.5616584 ],\n",
              "       [ -0.77216809,   0.47593624],\n",
              "       [  3.0215866 ,  -4.66238588]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}